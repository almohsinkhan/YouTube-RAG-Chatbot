{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c405e2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A great question!\\n\\nSo, you want to know what LangChain is? That's a fascinating topic! To answer your question, let me take a step back and break it down...\\n\\nLangChain is an AI-powered language model that combines the capabilities of multiple pre-trained language models to generate human-like text. It's like a supercharged version of traditional language models!\\n\\nHere's how it works: LangChain takes in prompts or questions and uses its advanced algorithms to combine the strengths of various language models, such as transformer-based models like BERT or RoBERTa. This allows it to generate responses that are more accurate, informative, and engaging than single models could produce on their own.\\n\\nThe key benefit of LangChain is its ability to handle complex queries and produce long-form text that's both coherent and meaningful. This makes it an excellent tool for tasks like language translation, content generation, and even creative writing!\\n\\nSo, there you have it! That's what LangChain is all about â€“ the power of combining AI models to create a truly remarkable language understanding and generation system!\\n\\nWhat do you think? Want to know more or explore its potential applications?\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "model = OllamaLLM(model=\"llama3\")\n",
    "\n",
    "chain = prompt | model\n",
    "\n",
    "chain.invoke({\"question\": \"What is LangChain?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa559d07",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'langchain_ollama' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mlangchain_ollama\u001b[49m.list_models()\n",
      "\u001b[31mNameError\u001b[39m: name 'langchain_ollama' is not defined"
     ]
    }
   ],
   "source": [
    "langchain_ollama.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c69fb66",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Ollama' from 'langchain_ollama' (/home/mohsinkhan/YouTube-RAG-Chatbot/venv/lib64/python3.14/site-packages/langchain_ollama/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_ollama\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Ollama\n\u001b[32m      3\u001b[39m ollama = Ollama()\n\u001b[32m      4\u001b[39m models = ollama.list_models()\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'Ollama' from 'langchain_ollama' (/home/mohsinkhan/YouTube-RAG-Chatbot/venv/lib64/python3.14/site-packages/langchain_ollama/__init__.py)"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import Ollama\n",
    "\n",
    "ollama = Ollama()\n",
    "models = ollama.list_models()\n",
    "print(models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcb4bb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
